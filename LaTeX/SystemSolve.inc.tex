% -*- TeX:UK -*-
\section{Solving systems of linear equations}

The system
\begin{equation}
\left\{
        \begin{array}{c@{\;}c@{\;}l}
           \AbsVec{a}_{11} \AbsVec{x}_{1} + \AbsVec{a}_{12} \AbsVec{x}_{2}  + \ldots + \AbsVec{a}_{1p} \AbsVec{x}_{p} & = & \AbsVec{b}_{1} \\
           \AbsVec{a}_{21} \AbsVec{x}_{1} + \AbsVec{a}_{22} \AbsVec{x}_{2}  + \ldots + \AbsVec{a}_{2p} \AbsVec{x}_{p} & = & \AbsVec{b}_{2} \\
           \ldots                                                                                                     &   & \ldots         \\
           \AbsVec{a}_{n1} \AbsVec{x}_{1} + \AbsVec{a}_{n2} \AbsVec{x}_{2}  + \ldots + \AbsVec{a}_{np} \AbsVec{x}_{p} & = & \AbsVec{b}_{n} \\
        \end{array}
\right.
\end{equation}
with known coefficients \(\arr{A} \), known right hand side \(\AbsVec{b}_{i} \) and unknown solutions \(\AbsVec{x} \) can be written in matrix terminology:
\begin{gather}
  \begin{pmatrix}
     \AbsVec{a}_{11} & \AbsVec{a}_{12} & \ldots & \AbsVec{a}_{1p} \\
     \AbsVec{a}_{21} & \AbsVec{a}_{22} & \ldots & \AbsVec{a}_{2p} \\
          \ldots     &                 &        &                 \\
     \AbsVec{a}_{n1} & \AbsVec{a}_{n2} & \ldots & \AbsVec{a}_{np}
  \end{pmatrix} \times
  \begin{pmatrix}
     \AbsVec{x}_{1}  &  \AbsVec{x}_{2} & \ldots & \AbsVec{x}_{p}
  \end{pmatrix} =
  \begin{pmatrix}
     \AbsVec{b}_{1} \\
     \AbsVec{b}_{2} \\
     \ldots         \\
     \AbsVec{b}_{n}
  \end{pmatrix}, \hspace{10mm}
  \arr{A}_{n\times p} \times \AbsVec{X}_{p} = \AbsVec{B}_{n}
\end{gather}
There should be as many equations as unknown (\( n = p \)), thus \arr{A} is square \parencite{Atk-83, Bor-86, Eng-87, Pre-89, Sed-83, Ste-73, Ren-02}.

\begin{lstlisting}[caption=Interface of SystemSolve]
  UNIT SystemSolve;

  INTERFACE

  USES Math, MathFunc, Vector, Matrix;

  CONST
    SystemError: StrArrayType = ('ok', 'dimension error', 'matrix singular',
      'MaxIter < 1', 'no conversion', 'evaluation short-circuited',
      '', 'matrix not symmetric', 'not enough memory', '', '', '');

  FUNCTION MakeUpperTriangular(VAR Koeff : MatrixTyp; VAR Right : VectorTyp) : BYTE;

  FUNCTION HadamardConditionNumber (VAR Mat : MatrixTyp) : double;

  FUNCTION GaussElimination(CONST Coefficients: MatrixTyp;
      VAR RightSide, Solution: VectorTyp): BYTE;

  FUNCTION PartialPivoting(CONST Coefficients: MatrixTyp;
      VAR RightSide, Solution: VectorTyp): BYTE;

  FUNCTION LU_Decompose(CONST Coefficients: MatrixTyp;
      VAR Decomp, Permute: MatrixTyp): BYTE;

  FUNCTION LU_Solve(CONST Decomp, Permute: MatrixTyp; CONST RightSide: VectorTyp;
      VAR Solution: VectorTyp): BYTE;

  FUNCTION Householder (CONST A : MatrixTyp; VAR Q, R : MatrixTyp) : BYTE;

  IMPLEMENTATION

  VAR CH  : CHAR;
\end{lstlisting}

\subsection{Private routines}

\begin{lstlisting}[caption=]
  FUNCTION MakeUpperTriangular(VAR Koeff : MatrixTyp; VAR Right : VectorTyp) : BYTE;

  VAR Multiplier               : double;
      Row, ReferenceRow, Dimen : WORD;

    FUNCTION Pivot(ReferenceRow: INTEGER) : BYTE;
          { This procedure searches the ReferenceRow column of the Coefficients
            matrix for the first non-MaxError element below the diagonal. If it
            finds one, then the procedure switches rows so that the non-MaxError
            element is on the diagonal. It also switches the corresponding
            elements in the Constants vector. If it doesn't find one, the
            matrix is singular and no solution exists (Error = 2 is returned). }

    VAR NewRow : INTEGER;
        Dummy  : double;

    BEGIN
      Result := 2;          { No solution exists }
      NewRow := ReferenceRow;
      WHILE (Result > 0) AND (NewRow < Dimen) DO
        BEGIN    { Try to find a row with a non-MaxError diagonal element    }
          NewRow := Succ(NewRow);
          IF Abs(GetMatrixElement(Koeff, NewRow, ReferenceRow)) > MaxError
            THEN
              BEGIN
                ExchangeRows(Koeff, NewRow, ReferenceRow);
                Dummy := GetVectorElement(Right, NewRow);
                SetVectorElement(Right, NewRow, GetVectorElement(Right, ReferenceRow));
                SetVectorElement(Right, ReferenceRow, Dummy);
                Result := 0;    { Solution may exist }
              END;
        END;
    END; { procedure Pivot }

  BEGIN { procedure UpperTriangular }
    Dimen := MatrixRows(Koeff);
    ReferenceRow := 0;
    Result := 0;
    WHILE ((Result = 0) AND (ReferenceRow < Pred(Dimen))) DO
      BEGIN
        INC(ReferenceRow);  { Check to see if the main diagonal element is MaxError }
        IF Abs(GetMatrixElement(Koeff, ReferenceRow, ReferenceRow)) < MaxError
          THEN Result := Pivot(ReferenceRow);
        IF Result = 0
          THEN
            FOR Row := Succ(ReferenceRow) TO Dimen DO
          { Make the ReferenceRow element of this row MaxError }
              IF Abs(GetMatrixElement(Koeff, Row, ReferenceRow)) > MaxError
                THEN
                  BEGIN
                    Multiplier := -GetMatrixElement(Koeff, Row, ReferenceRow) / GetMatrixElement(Koeff, ReferenceRow, ReferenceRow);
                    EROmultAdd(Koeff, Multiplier, ReferenceRow, Row);
                    SetVectorElement(Right, Row, GetVectorElement(Right, Row) + Multiplier * GetVectorElement(Right, ReferenceRow));
                  END;
      END; { while }
    IF Abs(GetMatrixElement(Koeff, MatrixRows(Koeff), MatrixColumns(Koeff))) < MaxError
      THEN Result := 2;    { No solution }
  END; { procedure UpperTriangular }
\end{lstlisting}

\begin{lstlisting}[caption=]
  PROCEDURE BackwardSubst (VAR Koeff : MatrixTyp; VAR Right, Solution : VectorTyp);
  { This procedure applies backwards substitution to the upper triangular
    Coefficients matrix and Constants vector. The resulting vector is the
    solution to the set of equations and is stored in the vector Solution. }

  VAR Term, Row, Dimen : WORD;
      Sum              : double;

  BEGIN
    Dimen := MatrixRows(Koeff);
    FOR Term := Dimen DOWNTO 1 DO
      BEGIN
        Sum := 0;
        FOR Row := Succ(Term) TO Dimen DO
          Sum := Sum + GetMatrixElement(Koeff, Term, Row) * GetVectorElement(Solution, Row);
        SetVectorElement(Solution, Term, (GetVectorElement(Right, Term) - Sum) / GetMatrixElement(Koeff, Term, Term));
    END;
  END; { procedure BackwardsSub }
\end{lstlisting}

\begin{lstlisting}[caption=Test if matrix is suitable]
  FUNCTION Initial(CONST Coefficients : MatrixTyp; VAR RightSide, Solution : VectorTyp) : BYTE;

  VAR Dimen : WORD;

  BEGIN
    Result := 0;
    Dimen := MatrixRows(Coefficients);
    IF ((Dimen < 1) OR (Dimen <> MatrixColumns(Coefficients)) OR (Dimen <> VectorLength(RightSide)))
      THEN
        Result := 1
      ELSE
        IF Dimen = 1
          THEN
            IF Abs(GetMatrixElement(Coefficients, 1, 1)) < MaxError
              THEN Result := 2
              ELSE SetVectorElement(Solution, 1, GetVectorElement(RightSide, 1) / GetMatrixElement(Coefficients, 1, 1));
  END; { procedure Initial }
\end{lstlisting}

\subsection{The condition number}

The matrix \arr{A} may  be well conditioned, that is, small changes in the elements \(\AbsVec{b} \) will produce only small changes in the solution \(\AbsVec{x} \). Ill conditioned matrices, on the other hand, produce large changes in the solution for small changes in \AbsVec{b}. If \AbsVec{e} is the error in \AbsVec{b} and \arr{A} is not singular, then the error of \(\arr{A}^{-1}\AbsVec{b} \) will be \(\arr{A}^{-1}\AbsVec{E} \) and the relative error will be
\begin{equation}
  \kappa(\arr{A}) = \frac{\frac{||\arr{A}^{-1}\AbsVec{E}||}{||\arr{A}^{-1}\AbsVec{B}||}}{\frac{||\AbsVec{E}||}{||\AbsVec{B}||}}
  = \left(\frac{||\arr{A}^{-1}\AbsVec{E}||}{||\AbsVec{E}||}\right) \left(\frac{||\AbsVec{B}||}{||\arr{A}^{-1}\AbsVec{B}||} \right) = ||\arr{A}^{-1}|| \times ||\arr{A}||
\end{equation}
\( \kappa \) is called the \textbf{condition number} of \arr{A}. Most commonly, the \Name{Frobenius}-norm is used for its calculation. Note that the condition number is a property of the matrix \arr{A}, not the algorithm used for its solution or the numerical precision of the computer.

\begin{lstlisting}[caption=Condition Number]
  FUNCTION HadamardConditionNumber (VAR Mat : MatrixTyp) : double;

  VAR n, i, j           : WORD;
      res               : BYTE;
      Decomp, Permute   : MatrixTyp;
      temp, cond        : double;

  BEGIN
    n := MatrixRows(Mat);
    IF NOT(MatrixSymmetric(Mat))
      THEN
        BEGIN
          CH := WriteErrorMessage(' Hadamard condition number of a non-symmetric matrix');
          Result := NaN;
          EXIT;
        END;
    res := LU_Decompose(Mat, Decomp, Permute);
    IF MatrixError
      THEN
        BEGIN
          Result := NaN;
          EXIT;
        END;
    IF res = 2
      THEN
        Result := 0    // singular matrix
      ELSE
        BEGIN
          cond := 1.0;
          FOR i := 1 TO n DO
            BEGIN
              temp := 0.0;
              FOR j := 1 TO n DO
                temp := temp + Sqr(GetMatrixElement(Mat, i, j));
              cond := cond * GetMatrixElement(Decomp, i, i) / Sqrt(temp);
            END;
          Result := Abs(cond);
        END;
    DestroyMatrix(Decomp);
    DestroyMatrix(Permute);
  END;
\end{lstlisting}

\subsection{Over- and under-determined systems}

If there are more (independent) equations \skalar{n} than unknowns \skalar{p} (overdetermined system) we have an error-minimisation (linear least squares) problem. If there are fewer equations than unknowns (or some equations are linear combinations), then there will be \(p-n \) solution vectors (underdetermined system). These situations can be handled with singular value decomposition.

The routines for system solving return the following error codes:

\begin{tabular}{ll}
  0 & everything ok \\
  1 & dimension error (number of vars \(\neq \) number of equations) \\
  2 & matrix singular \\
  3 & MaxIter < 0 \\
  4 & MaxIter exceeded \\
  5 & evaluation short-circuited  \\
  6 &  \\
  7 & matrix not symmetric \\
  8 & not enough memory \\
\end{tabular}

\subsection{Example}
\begin{gather}
  \begin{pmatrix}
      1.00 & 2.00 & 0.00 & -1.00 \\
     -1.00 & 4.00 & 3.00 & -0.50 \\
      2.00 & 2.00 & 1.00 & -3.00 \\
      0.00 & 0.00 & 3.00 & -4.00
  \end{pmatrix} \times
  \begin{pmatrix}
     -1.00 & 2.00 & 3.00 -7.00
  \end{pmatrix} =
  \begin{pmatrix}
     10.0 \\
     21.5 \\
     26.0 \\
     37.0
  \end{pmatrix}
\end{gather}


\subsection{\Name{Gauss}ian elimination}

The \Name{Gauss}ian elimination method is used to solve systems of equations. The matrix is converted into the upper triangular form, then the solution is calculated by back-substitution (\( \AbsVec{x}_m, \AbsVec{x}_{m-1}\ldots \AbsVec{x}_1 \)). The system has no solution if one or more diagonal elements of the triangular matrix are zero (singular matrix). The method is fast, but sensitive to rounding errors when elements of the diagonal are small compared to elements below them in the same column.

\begin{lstlisting}[caption=]
  FUNCTION GaussElimination(CONST Coefficients : MatrixTyp;
    VAR RightSide, Solution : VectorTyp) : BYTE;

  VAR Error : BYTE;
      Dimen : WORD;
      Koeff : MatrixTyp;
      Right : VectorTyp;

  BEGIN { procedure Gaussian_Elimination }
    Dimen := MatrixRows(Coefficients);
    Result := Initial(Coefficients, RightSide, Solution);
    IF result <> 0 THEN EXIT;
    CreateVector(Right, Dimen, 0.0);
    CreateVector(Solution, Dimen, 0.0);
    CopyVector(RightSide, Right);
    IF VectorError
      THEN
        BEGIN
          VectorError := FALSE;
          Result := 8;
          EXIT;
        END;
    CopyMatrix(Coefficients, Koeff);
    IF MatrixError
      THEN
        BEGIN
          MatrixError := FALSE;
          Result := 8;
          EXIT;
        END;
    IF MatrixRows(Koeff) > 1
      THEN
        BEGIN
          Error := MakeUpperTriangular(Koeff, Right);
          IF Error = 0 THEN BackwardSubst(Koeff, Right, Solution);
        END;
    Result := Error;
    DestroyVector(Right);
    DestroyMatrix(Koeff);
  END; { procedure Gaussian_Elimination }
\end{lstlisting}

\subsection{\Name{Gauss}-elimination with partial pivoting}

In this method lines of matrix and right side are exchanged to ensure that all diagonal elements are larger than the elements below them. This method is more stable, but slower than the simple \Name{Gauss} elimination.

\begin{lstlisting}[caption=]
  FUNCTION PartialPivoting(CONST Coefficients: MatrixTyp;
    VAR RightSide, Solution: VectorTyp): BYTE;

  VAR Error : BYTE;
      Dimen : WORD;
      Koeff : MatrixTyp;
      Right : VectorTyp;

  BEGIN  { procedure PartialPivoting }
    Dimen := MatrixRows(Coefficients);
    Result := Initial(Coefficients, RightSide, Solution);
    IF result <> 0 THEN EXIT;
    CopyMatrix(Coefficients, Koeff);
    IF MatrixError
      THEN
        BEGIN
          MatrixError := FALSE;
          Result := 8;
          EXIT;
        END;
    CreateVector(Solution, Dimen, 0.0);
    CopyVector(RightSide, Right);
    IF VectorError
      THEN
        BEGIN
          VectorError := FALSE;
          Result := 8;
          EXIT;
        END;
    IF Dimen > 1
      THEN
        BEGIN
          Error := MakeUpperTriangular(Koeff, Right);
          IF Error = 0 THEN BackwardSubst(Koeff, Right, Solution);
        END;
    Result := Error;
    DestroyMatrix(Koeff);
    DestroyVector(Right);
  END; { Partial_Pivoting }
\end{lstlisting}

\subsection{LU-decomposition}

The matrix \arr{A} is decomposed into a upper triangular matrix \arr{U} and a lower triangular matrix \arr{L}. Then
\begin{equation}
  \arr{L} \times \arr{U} = \arr{A}
\end{equation}
and
\begin{equation}
  \arr{A} \times \AbsVec{X} = (\arr{L} \times \arr{U}) \times \AbsVec{X} = \arr{L} \times (\arr{U} \times \AbsVec{X}) = \AbsVec{B}
\end{equation}
Taking advantage of the triangular shape of \arr{L} and \arr{U}, we first solve for \(\arr{L} \AbsVec{Y} = \AbsVec{B} \), then for \(\arr{U} \AbsVec{X} = \AbsVec{Y} \). This algorithm is only \(O(n^2) \), and once the decomposition has been performed, it can be used to solve for several right hand sides, if desired.

\begin{lstlisting}[caption=LU-decomposition]
  FUNCTION LU_Decompose(CONST Coefficients : MatrixTyp; VAR Decomp, Permute : MatrixTyp): BYTE;

  VAR Error: BYTE;
      Koeff, Upper, Lower: MatrixTyp;
      Dimen: WORD;


    FUNCTION RowColumnMult(VAR Lower, Upper: MatrixTyp; Row, Column: WORD): double;
      { Function return: dot product of row Row of Lower and column Column of Upper }

    VAR Term : INTEGER;
        Sum  : double;

    BEGIN
      Sum := 0;
      FOR Term := 1 TO Pred(Row) DO
        Sum := Sum + GetMatrixElement(Lower, Row, Term) * GetMatrixElement(Upper, Term, Column);
      Result := Sum;
    END; { RowColumnMult }


    PROCEDURE Pivot(ReferenceRow: WORD; VAR Error: BYTE);
       { This procedure searches the ReferenceRow column of the Coefficients
         matrix for the element in the Row below the main diagonal which
         produces the largest value of Coefficients[Row, ReferenceRow] - Sum
         (for K=1 to pred(ReferenceRow) of Upper[Row, k] - Lower[k, ReferenceRow]
        If it finds one, then the procedure switches rows so that this element
        is on the main diagonal. The procedure also switches the corresponding
        elements in the Permute matrix and the Lower matrix. If the largest
        value of the above expression is MaxError, then the matrix is singular and
        no solution exists (Error = 2 is returned).   }

    VAR PivotRow, Row      : WORD;
        ColumnMax, TestMax : double;

    BEGIN { procedure Pivot }
      { First, find the row with the largest TestMax }
      PivotRow := ReferenceRow;
      ColumnMax := Abs(GetMatrixElement(Koeff, ReferenceRow, ReferenceRow) -
        RowColumnMult(Lower, Upper, ReferenceRow, ReferenceRow));
      FOR Row := Succ(ReferenceRow) TO Dimen DO
        BEGIN
          TestMax := Abs(GetMatrixElement(Koeff, Row, ReferenceRow) - RowColumnMult(Lower, Upper, Row, ReferenceRow));
          IF TestMax > ColumnMax
            THEN
              BEGIN
                PivotRow := Row;
                ColumnMax := TestMax;
              END;
        END;
      IF PivotRow <> ReferenceRow
        THEN   { Second, switch these two rows }
          BEGIN
            ExchangeRows(Koeff, PivotRow, ReferenceRow);
            ExchangeRows(Lower, PivotRow, ReferenceRow);
            ExchangeRows(Permute, PivotRow, ReferenceRow);
          END
        ELSE { If ColumnMax is MaxError, no solution exists }
          IF ColumnMax < MaxError
            THEN Error := 2;
    END; { procedure Pivot }


    PROCEDURE Decompose(VAR Error: BYTE);
       { This procedure decomposes the Coefficients matrix into two triangular
         matrices, a lower and an upper one.  The lower and upper matrices are
         combined into one matrix, Decomp.  The permutation matrix, Permute,
         records the effects of partial pivoting.  }

    VAR Term, Index: INTEGER;

      PROCEDURE Initialize;
            { This procedure initializes Lower and Upper to the MaxError matrix
              and Permute to the identity matrix. }

      BEGIN
        CreateMatrix(Upper, Dimen, Dimen, 0.0);
        CreateMatrix(Lower, Dimen, Dimen, 0.0);
        CreateIdentityMatrix(Permute, Dimen);
        IF MatrixError
          THEN
            BEGIN
              MatrixError := FALSE;
              Error := 8;
            END;
      END; { procedure Initialize }

    BEGIN { Decompose }
      Initialize;
      { partial pivoting on row 1 }
      Pivot(1, Error);
      IF Error = 0
        THEN
          BEGIN
            SetMatrixElement(Lower, 1, 1, 1);
            SetMatrixElement(Upper, 1, 1, GetMatrixElement(Koeff, 1, 1));
            FOR Term := 1 TO Dimen DO
              BEGIN
                SetMatrixElement(Lower, Term, 1, GetMatrixElement(Koeff, Term, 1) / GetMatrixElement(Upper, 1, 1));
                SetMatrixElement(Upper, 1, Term, GetMatrixElement(Koeff, 1, Term) / GetMatrixElement(Lower, 1, 1));
              END;
          END;
      Term := 1;
      WHILE (Error = 0) AND (Term < Pred(Dimen)) DO
        BEGIN
          Term := Succ(Term); { perform partial pivoting on row Term }
          Pivot(Term, Error);
          SetMatrixElement(Lower, Term, Term, 1);
          SetMatrixElement(Upper, Term, Term,
             GetMatrixElement(Koeff, Term, Term) - RowColumnMult(Lower, Upper, term, term));
          IF Abs(GetMatrixElement(Upper, Term, Term)) < MaxError
            THEN
              Error := 2   { no solutions }
            ELSE
              FOR Index := Succ(Term) TO Dimen DO
                BEGIN
                  SetMatrixElement(Upper, Term, Index, GetMatrixElement(Koeff, Term, Index) - RowColumnMult(Lower, Upper, Term, Index));
                  SetMatrixElement(Lower, Index, Term, (GetMatrixElement(Koeff, Index, Term) - RowColumnMult(Lower, Upper, Index, Term)) /
                      GetMatrixElement(Upper, Term, Term));
                END;
        END;
      SetMatrixElement(Lower, Dimen, Dimen, 1);
      SetMatrixElement(Upper, Dimen, Dimen, GetMatrixElement(Koeff, Dimen, Dimen) - RowColumnMult(Lower, Upper, Dimen, Dimen));
      IF Abs(GetMatrixElement(Upper, Dimen, Dimen)) < MaxError THEN Error := 2;
      { Combine the upper and lower triangular matrices into one }
      CopyMatrix(Upper, Decomp);
      FOR Term := 2 TO Dimen DO
        FOR Index := 1 TO Pred(Term) DO
          SetMatrixElement(Decomp, Term, Index, GetMatrixElement(Lower, Term, Index));
      DestroyMatrix(Upper);
      DestroyMatrix(Lower);
    END; { procedure Decompose }

  BEGIN { LU_Decompose }
    Dimen := MatrixRows(Coefficients);
    CopyMatrix(Coefficients, Koeff);
    IF MatrixError
      THEN
        BEGIN
          MatrixError := FALSE;
          Result := 8;
          EXIT;
        END;
    IF Dimen < 1
      THEN
        Error := 1
      ELSE
        BEGIN
          Error := 0;
          IF Dimen = 1
            THEN
              BEGIN
                CopyMatrix(Koeff, Decomp);
                SetMatrixElement(Permute, 1, 1, 1);
              END
            ELSE
              Decompose(Error);
        END;
    Result := Error;
    DestroyMatrix(Koeff);
  END; { LU_Decompose }
\end{lstlisting}

\begin{lstlisting}[caption=Solve system]
  FUNCTION LU_Solve(CONST Decomp, Permute : MatrixTyp; CONST RightSide : VectorTyp;
                    VAR Solution : VectorTyp): BYTE;

  VAR Error    : BYTE;
      Dimen    : WORD;
      DEC, Per : MatrixTyp;
      Right    : VectorTyp;


    PROCEDURE FindSolution;
       { The Decom matrix contains a lower and upper triangular matrix. This
         procedure performs a two step backwards substitution to compute the
         solution to the system of equations.  First, forward substitution is
         applied to the lower triangular matrix and Constants vector yielding
         PartialSolution.  Then backwards substitution is applied to the Upper
         matrix and the PartialSolution vector yielding Solution.  }

    VAR PartialSolution : Vectortyp;
        Term, Index     : WORD;
        Sum             : double;

    BEGIN { FindSolution }
      { First solve the lower triangular matrix }
      CreateVector(PartialSolution, Dimen, 0.0);
      SetVectorElement(PartialSolution, 1, GetVectorElement(Right, 1));
      FOR Term := 2 TO Dimen DO
        BEGIN
          Sum := 0;
          FOR Index := 1 TO Pred(Term) DO
            IF Term = Index
            THEN
              Sum := Sum + GetVectorElement(PartialSolution, Index)
            ELSE
              Sum := Sum + GetMatrixElement(DEC, Term, Index) * GetVectorElement(PartialSolution, Index);
          SetVectorElement(PartialSolution, Term, GetVectorElement(Right, Term) - Sum);
        END;
      { Then solve the upper triangular matrix }
      SetVectorElement(Solution, Dimen, GetVectorElement(PartialSolution,Dimen) / GetMatrixElement(DEC, Dimen, Dimen));
      FOR Term := Pred(Dimen) DOWNTO 1 DO
        BEGIN
          Sum := 0;
          FOR Index := Succ(Term) TO Dimen DO
            Sum := Sum + GetMatrixElement(DEC, Term, Index) * GetVectorElement(Solution, Index);
          SetVectorElement(Solution, Term, (GetVectorElement(PartialSolution, Term) - Sum) / GetMatrixElement(DEC, Term, Term));
        END;
      DestroyVector(PartialSolution);
    END; { procedure FindSolution }


    PROCEDURE PermuteRightSide;

    VAR Row, Column   : WORD;
        Entry         : double;
        TempConstants : VectorTyp;

    BEGIN
      CreateVector(TempConstants, Dimen, 0.0);
      FOR Row := 1 TO Dimen DO
        BEGIN
          Entry := 0;
          FOR Column := 1 TO Dimen DO
            Entry := Entry + GetMatrixElement(Per, Row, Column) * GetVectorElement(Right, Column);
          SetVectorElement(TempConstants, Row, Entry);
        END;
      CopyVector(TempConstants, Right);
      DestroyVector(TempConstants);
    END; { PermuteRightSide }

  BEGIN { Solve_LU_Decompostion }
    Dimen := MatrixRows(Decomp);
    CopyMatrix(Decomp, DEC);
    CopyMatrix(Permute, Per);
    CreateVector(Solution, Dimen, 0.0);
    IF MatrixError
      THEN
        BEGIN
          MatrixError := FALSE;
          Result := 8;
          EXIT;
        END;
    CopyVector(RightSide, Right);
    IF VectorError
      THEN
        BEGIN
          VectorError := FALSE;
          Result := 8;
          EXIT;
        END;
    IF Dimen < 1
      THEN
        Error := 1
      ELSE
        BEGIN
          Error := 0;
          PermuteRightSide;
          FindSolution;
        END;
    Result := Error;
    DestroyMatrix(DEC);
    DestroyMatrix(Per);
  END; { procedure LU_Solve }
\end{lstlisting}


\subsection{The QR-factorisation}

The QR-factorisation decomposes a \(\arr{A}_{n\times p} \)-matrix (\( n \geq p \)) into the product of an unitary (orthogonal if \arr{A} is square, real and of full rank) matrix \(\arr{Q}_{n\times n} \) (\Foreign{i.e.}, \(\arr{QQ}^T = \arr{Q}^T\arr{Q} = \arr{I} \)) and an upper triangular matrix \(\arr{R}_{n\times p} \):
\begin{equation}
  \arr{A} = \arr{QR}
\end{equation}
The bottom \((n-p) \) rows of \arr{R} consist entirely of zeroes. Then
\begin{equation}
  \arr{A} = \arr{QR} = \arr{Q} \begin{pmatrix}
                                  \hat{\arr{R}} \\
                                  \mathbf{0}
                               \end{pmatrix}
\end{equation}
The upper triangular matrix \(\hat{\arr{R}}_{p\times p} \) is regular with diagonal elements \(\hat{\arr{R}}_{ii} \neq 0 \) if \(\mathrm{rk}(\arr{A}) = p \) (see below).

The factorisation is used to calculate linear least-square and eigenvalue problems. Also, since \(\det(\arr{A}) = \det(\arr{Q}) * \det(\arr{R}) \) and \(\det(\arr{Q}) = \pm 1 \), \(|\det(\arr{A})| = |\det(\arr{R})| = |\prod_{i=1}^p{\skalar{r}_{ii}}| = |\prod_{i=1}^p{\sigma_{ii}}| \) (or \(|\prod_{i=1}^p{\lambda_{ii}}| \) if \arr{A} is square). Thus, QR-factorisation can be used to cheaply calculate the products of singular or eigenvalues of \arr{A}. Because \arr{QR} have better condition numbers than \arr{A}, this factorisation is also used for linear inverse problems.

It is also possible to work with a lower triangular matrix \arr{L}, or to exchange the matrices (RQ-, QL- and LQ-factorisation).

There are three important methods for QR-factorisation:
\begin{description}
  \item[\Name{Gram–Schmidt} process]{easy to implement, but numerically unstable}
  \item[\Name{Householder} reflection]{medium complexity, stable, not parallelisable}
  \item[\Name{Givens} rotation]{complex to implement, stable, parallelisable}
\end{description}
Since we need a stable algorithm, but haven't worried about parallelisation with any of the other routines, we'll use \Name{Householder} reflection.

\subsubsection{\Name{Householder} reflection}

Multiplication of a vector, for example the \skalar{k}-th column vector of \arr{A}, \(\AbsVec{a}_{\cdot,k} \), with a \Name{Householder} matrix
\begin{equation}
  \arr{H} = \arr{I} - \frac{2}{\AbsVec{u}^T \odot \AbsVec{u}}\enspace \AbsVec{u} \otimes \AbsVec{u}^T
\end{equation}
reflects this vector by a plane defined by its normal \AbsVec{u}. Note that \(\AbsVec{u} \otimes \AbsVec{u}^T \) is the outer (dyadic) product, and hence a matrix, while \(\AbsVec{u}^T \odot \AbsVec{u} \) is the inner (dot) product of the vectors and hence a scalar. \(\frac{2}{\AbsVec{u}^T \odot \AbsVec{u}} = \frac{1}{||u||_2 (||u||_2 +1)} \).

For the first column vector of \arr{A} we use \(\AbsVec{u} = \AbsVec{a}_{\cdot,1} - \alpha \AbsVec{e} \) with the first standard basis vector of length \skalar{n}, \(\AbsVec{e} = (1, 0,\ldots 0)^T \) (only the first element is 1, the rest 0) and \(\alpha = ||\AbsVec{a}_{\cdot,1}||_2 \) the \Name{Euklid}ian norm to set all elements after the first to zero. To avoid cancellation errors, we modify this equation by the opposite sign of the pivot element \(\arr{A}_{k,k} \):
\begin{equation}
  \AbsVec{u} = \AbsVec{a}_{\cdot,1} - \sgn(\AbsVec{a}_{1,1}) \alpha \AbsVec{e}_1
\end{equation}
Then we normalise this vector by its first element:
\begin{equation}
   \AbsVec{v} = \frac{\AbsVec{u}}{\AbsVec{u}_1}
\end{equation}
Then the first \Name{Householder}-matrix becomes:
\begin{equation}
  ^1\arr{H} = \arr{I} - \frac{2}{\AbsVec{v}^T \odot \AbsVec{v}}\enspace \AbsVec{v} \otimes \AbsVec{v}^T = \arr{I} - \beta \enspace \AbsVec{v} \otimes \AbsVec{v}^T
\end{equation}
The first step zeros all subdiagonal elements of the first column:
\begin{equation}
   ^1\arr{H} \arr{A} = \begin{pmatrix}
                                  \skalar{r}_{1,1} & \skalar{r}_{1,2} &  \ldots & \skalar{r}_{1,p} \\
                                  0                & *                &  \ldots & *                \\
                                  \vdots           & *                &  \ldots & *                \\
                                  0                & *                &  \ldots & *                \\
                               \end{pmatrix}
\end{equation}
This process is repeated in the second step on the submatrix \arr{A}' (the elements marked with a star above), resulting in a \Name{Householder}-matrix \(^2\arr{H} \)'. Since we really want to apply this matrix on \arr{A} rather than \arr{A}', we need to embed into an identity matrix \(\arr{I}_{n\times p} \):
\begin{equation}
  ^2\arr{H} = \begin{pmatrix}
                                  1       & 0           &  \ldots & 0 \\
                                  0       & ^2\arr{H}'  &         &   \\
                                  \vdots  &             &         &   \\
                                  0       &             &         &   \\
                               \end{pmatrix}
\end{equation}
Thus, in \(\min(n-1, p) \) operations we can remove all subdiagonal elements of \arr{A}, turning it into \arr{R}:
\begin{align}
  \arr{R} &= ^n\arr{H} \ldots ^3\arr{H} ^2\arr{H} ^1\arr{H} \arr{A} \\
  \arr{Q} &= ^1\arr{H} ^2\arr{H} ^3\arr{H} \ldots ^n\arr{H}
\end{align}
This algorithm is \textbf{O} \( (n^3) \) and described in detail on \parencite{Ros-18, Lub-04}.

Example: the \Name{Hilbert}-matrix with \(n = 4 \) gives
\begin{eqnarray}
  \arr{A} =&
  \begin{pmatrix}
     1.0000 & 0.5000 & 0.3333 & 0.2500 \\
     0.5000 & 0.3333 & 0.2500 & 0.2000 \\
     0.3333 & 0.2500 & 0.2000 & 0.1667 \\
     0.2500 & 0.2000 & 0.1667 & 0.1429
  \end{pmatrix} \\
  \arr{R} =&
  \begin{pmatrix}
     1.193   &  0.6705 &  0.4749  &  0.3698 \\
     0.0000  & -0.1185 & -0.1257  & -0.1175 \\
     0.0000  &  0.0000 &  0.0062  &  0.0096 \\
     0.0000  &  0.0000 &  0.0000  & -0.0002
  \end{pmatrix} \\
  \arr{Q} =&
  \begin{pmatrix}
     0.8381  &  0.5226 & -0.1540  &  0.0261 \\
     0.4191  & -0.4417 &  0.7278  & -0.3157 \\
     0.2794  & -0.5288 & -0.1395  &  0.7892 \\
     0.2095  & -0.5021 & -0.6536  & -0.5261
   \end{pmatrix}
\end{eqnarray}
The maximum difference between the original \Name{Hilbert} matrix and the product \arr{QR} is \num{e-16} when the calculation is performed in double precision.

\begin{lstlisting}[caption=QR-factorisation by Householder]
  FUNCTION Householder (CONST A : MatrixTyp; VAR Q, R : MatrixTyp) : BYTE;

  VAR Rows, Columns,
      i, j, k          : WORD;
      c                : CHAR;
      alpha, beta      : double;
      x, u, e          : VectorTyp;
      Identity, Product,
      H, Hs            : MatrixTyp;

  BEGIN
    Rows := MatrixRows(A);
    Columns := MatrixColumns(A);
    IF Rows < Columns
      THEN
        BEGIN
          c := WriteErrorMessage('QR decomposition of matrix with more columns than rows');
          MatrixError := TRUE;
          Householder := 1;                        // dimension error
          EXIT;
        END;
    CreateIdentityMatrix(Q, Rows);                 // neutral element OF matrix multiplication
    IF MatrixError THEN EXIT;
    CopyMatrix(A, R);                              // so that A IS unchanged
    IF MatrixError THEN EXIT;
    FOR j := 1 TO min(Pred(Rows), Columns) DO      // calculate j-th Householder Matrix
      BEGIN
        CreateVector(x, Succ(Rows-j), 0.0);
        FOR i := j TO Rows DO
          BEGIN
            k := Succ(i-j);
            SetVectorElement(x, k, GetMatrixElement(R, i, j));
          END;
        alpha := -Signum(GetVectorElement(x, 1)) * VectorEuklidianNorm(x);
        CreateVector(e, Succ(Rows-j), 0.0);
        SetVectorElement(e, 1, alpha);
        VectorAdd(x, e, u);                        // u = x + sgn(x_1) * ||x||_2 * (1, 0, ..., 0)
        DestroyVector(x);
        DestroyVector(e);
        DivConstant(u, Abs(GetVectorElement(u, 1))); // scale u by Abs(first element) -> v
        beta := 2 / VectorInnerProduct(u, u);      // \beta = 2 / (v \odot v)
        DyadicVectorProduct(u, u, Product);        // v \omul v
        DestroyVector(u);
        SkalarMultiplikation(Product, -beta);      //  beta * (v\omul v)
        CreateIdentityMatrix(Identity, Succ(Rows-j));
        MatrixAdd(Identity, Product, hs);          // Hs = I - beta * (v\omul v)
        DestroyMatrix(Identity);
        DestroyMatrix(Product);
        CreateIdentityMatrix(H, Rows);
        FOR i := j TO Rows DO                      // Copy Hs into lower right corner OF H
          FOR k := j TO Columns DO
            SetMatrixElement(H, i, k, GetMatrixElement(Hs, i-Pred(j), k-Pred(j)));
        MatrixInnerProduct(H, R, Product);         // R = HR
        DestroyMatrix(R);
        CopyMatrix(Product, R);
        DestroyMatrix(Product);
        MatrixInnerProduct(Q, H, Product);         // Q = QH
        DestroyMatrix(Q);
        CopyMatrix(Product, Q);
        DestroyMatrix(Product);
      END;
    Result := 0;                                   // everything ok
  END;


  END.   // SystemSolve
\end{lstlisting}

\subsection{Matrix rank}

The column rank of a matrix \(\mathrm{rk}(\arr{A}_{n\times p}), n \geq\ p \) is the number of linearly independent columns, the row rank the number of independent rows. Both are always equal, and at most the smaller of \(n \) and \(p \): \(\mathrm{rk}(\arr{A}_{n\times p}) \leq \min{(n, p)} \). For example,
\begin{gather}
  \mathrm{rk} \begin{pmatrix}
        1 &  2 & 1 \\
       -2 & -3 & 1 \\
        3 &  5 & 0
     \end{pmatrix} = 2
\end{gather}
because \(\AbsVec{a}_{3\cdot} = \AbsVec{a}_{1\cdot} - \AbsVec{a}_{2\cdot} \). The rank can be determined from the number of singular values larger than a certain threshold, if there is a noticeable gap in the singular value spectrum of \arr{M}. The matrix rank is also the number of positive eigenvalues of a square matrix.

An alternative method to determine rank is to perform a QR- (or LU-) decomposition of the matrix and then identify the number of rows with row-sums \(> \) 0. The procedure is sensitive to rounding errors, \textbf{strong rank-revealing QR- (or LU-) decomposition} algorithms need to be used. If \(\mathrm{rk}(\arr{A}_{n\times p}) \approx p \)  we speek of a high-rank matrix, if \(\mathrm{rk}(\arr{A}_{n\times p}) \approx 1 \) of a low rank matrix. Intermediate cases with \(\mathrm{rk}(\arr{A}_{n\times p}) \approx p/2 \) cause numerical trouble. Algorithms are given in \parencite{Mar-15, Gu-96}, the R-function \texttt{qr(matrix)\$rank} is \emph{not} rank-revealing!

\paragraph{Aside: Rank of rectangular matrices}

If the rank of a rectangular matrix \(\mathrm{rk}(\arr{A}_{n\times p}) = p \), the matrix would be of full rank, but will have linearly dependent rows if \(n > p \). Then there must exist a column vector \(\AbsVec{c}_p \) such that \(\arr{A}\AbsVec{c} = \mathbf{0} \). Although both \(\arr{A} \neq \mathbf{0} \) and \(\AbsVec{c} \neq \mathbf{0} \), their product is! Similarly, it is possible to construct rectangular matrices \(\arr{A, B, C} \) such that \(\arr{AB} = \arr{CB} \) even though \(\arr{A} \neq \arr{C} \). Thus, in matrix algebra, it is not possible to cancel matrices from both sides of an equation, except in special cases.

